# When changes made to auth server
to delete user (admin) via terminal - mysql -uroot -e "DROP USER auth_user@localhost"
to delete database auth via terminal - mysql -uroot -e "DROP DATABASE auth"
to run mysql via termial - mysql -uroot
to run mysql with the init.sql file created - mysql -uroot < init.sql
to start mysql server - brew services start mysql

# MySQL -uroot nav
show databases;
use auth (database name);
show tables;
describe user (table name);

# Basic Auth
1. outside world has no access to the private kubernetes network
2. therefore need to send requests to gateways, in order to let them use of the distributed system deployed in the private kubernetes clusters.
3. gateways is where we can add functionalities for the application (login, upload, etc in the server.py file)
4. Auth services are used to determine when to give access from the outside world.
5. This is done by creating creds in the auth db. 
6. If there is a match, a jwt is send back to the client. 
7. In summary, the client transmits credentials as user ID/password pairs, encoded using base64 to server to validate. 

# JWT
1. Has three parts (header, payload, verify signature)
2. Each path is Base64 encoded. 
    a. header 
    -> Contain key value pair of the signing algorithm(HS256) and typ(jwt)
    -> User logs in, auth service creates a jwt, signed using the private key (using HS256, a symmetric signing algo that uses 1 private key) and sent back to the user.
    -> Therefore the next time the user logs in, the jwt token is sent too, and the auth server verifies it, only then the user has access to the resources. 
    b. payload
    -> Contains "claims", some are user defined (username, password) and some are not (jwt expiration date).
    c. signature
    -> created by taking 
        HS256 ( 
        base64(header) + base64(payload) + 256-bit-secret 
        )
    -> the secret we define as an enviroment var.
    -> the jwt token sent by out cleint can be verified if it was signed by our private key and our signing algorithm. If so, we can check the clients access levels by decoding the payload.

# Server as a docker container 
1. Our server wil be a docker container, and the application will be in the container.
2. When Docker container is switched on, it will be given its own ip address (inside the docker network).
3. Use this ip address to send requests to the container, that is our server.
4. But we have to tell our Flask server to listen to the docker container for requests. 
5. Host config, its the server we are hosting our application in (the server that is hosting our flask application is the docker container it is running in).
6. But the docker containers ip address is subject to change, therefore setting it to 0.0.0.0, telling the flask application to listen to any/all our docker containers ip addresses.
7. If this is not done, it will default to localhost, so can listen to only requests from within the server, and not listen to requests from outside the server (as is not publicly accessable)
8. After setting the host ip to 0.0.0.0, the flask app will listen to all the requests incoming to the application, even if the container is part of 2 different docker networks.

# Authorization headers
1. Authorization <type> <credentials>
2. type == basic -> username:password pairs | type == bearer -> token 

# docker
1. Each intruction in the dockerfile results in a single new image layer being created, therefore the next intructions image layer will be built upon the previous image layer.
2. Therefore if a layer needs to change, the layers before need not change, only the current changed layer and the layer after it has to be rebuilt.
3. Previous layers are retained using cache. 
   
   Commands for Dockerfile:
   1. Create dockerfile 
   2. Build dcokerfile: docker build .
   3. Tag dockerfile: docker tag <tag number> username/reponame:latest
   4. Push dockerfile: docker push username/reponame:latest

# kubernetes
1. Helped with load balancing and auto scaling.
2. Read kubernetes docs for more information - https://kubernetes.io/docs/reference/kubernetes-api/
3. Kubernetes has pods, that hold Docker images. 
4. Kubernetes objects are yaml files that specify the specifications of the pods. 
5. Each obejct has different specifitions, depending on the "kind".

    Commands for Kubernetes - 
    1. k9s to check clusters
    2. kubectl apply -f ./ (creates/updates resources; added services)

# mongoDB (PyMongo) and GridFs
1. GridFs is used to store BSON files exceeding 16mb (MongoDB doesnt allow this, limitation) by sharding it and storing it as separate document.

# Overall Architecture:
1. Client is verified by Auth service using JWT tokens.
2. After authurization, the video is sent via the gateway, and is stored in MongoDB.
3. A message is sent to the queue, therefore the downstream services know there is a video to be processed.
4. The convertor service gets the message from the queue, gets the ID of the video from MongoDB, converts the file and stores the MP3 to MongoDB.
5. A new message is then sent through the queue to the notification service which notifies the client that the MP3 file is ready via email (contains MP3 ID)
6. The cleint then sends a request with the ID and JWT to download the MP3 to the gateway service.
7. The gateway service then returns the file to be downloaded. 

# Interservice communications:
    1. Synchronous - Client is blocked until the server responds (gateway to auth)
    2. Asynchronous - Non blocking request, client is not blocked and need not wait till the server responds. Achieved using queue (gateway to conversion, conversion to notification)

# Consistency:
    1. Strong consistency: Makes sure the request is sent directly to the service and is sent back to the client. Makes sure the client gets the latest data (Client -> conversion service -> Client). Higer latency.
    2. Eventual consistency: Our architecture. The data might not be readily available but, after a certain time, it will be. Lower latency.
     
# rabbitMQ
1. Can configure multiple queues in one RabbitMQ instance.
2. Our architure - a video queue and a mp3 queue.
3. The exchange route messages to correct queue based on certiain creteria.
4. Default exchange is an empty string (exchange: ""), there the routing key can be set to the name of the queue name.
5. There are more messages than the consumer can handle, RMQ scales up the customer. This is done by competing consumers pattern.
6. Competing consumers patterns allows multiple concurrent consumers to recieve messages from the same messages channel.
7. Done using round robin algorithm.









